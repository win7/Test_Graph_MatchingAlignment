{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphMatching import *\n",
    "from networkx import read_edgelist\n",
    "from scipy.io import loadmat\n",
    "from model import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import ConnectionPatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_matching(truth, test):\n",
    "    matching = []\n",
    "    test = test.tolist()\n",
    "    truth = truth.tolist()\n",
    "\n",
    "    for item in test:\n",
    "        if item in truth:\n",
    "            matching.append(item)\n",
    "    return matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"ACM_DBLP\" # args.dataset\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "train_features = {}\n",
    "if (data == \"ACM_DBLP\"):\n",
    "    train_set = [\"ACM\", \"DBLP\"]\n",
    "    input_dim = 17\n",
    "    b = np.load('data/ACM-DBLP.npz')\n",
    "    train_features[\"ACM\"] = [torch.from_numpy(b[\"x1\"]).float()]\n",
    "    train_features[\"DBLP\"] = [torch.from_numpy(b[\"x2\"]).float()]\n",
    "    test_pairs = b['test_pairs'].astype(np.int32)\n",
    "    NUM_HIDDEN_LAYERS = 12\n",
    "    HIDDEN_DIM = 1024\n",
    "    output_feature_size = 1024\n",
    "    lr = 0.0001\n",
    "    epoch = 100\n",
    "elif (data == \"Douban Online_Offline\"):\n",
    "    a1, f1, a2, f2, test_pairs = load_douban()\n",
    "    f1 = f1.A\n",
    "    f2 = f2.A\n",
    "    train_set = [\"Online\", \"Offline\"]\n",
    "    input_dim = 538\n",
    "    test_pairs = torch.tensor(np.array(test_pairs, dtype=int)) - 1\n",
    "    test_pairs = test_pairs.numpy()\n",
    "    train_features[\"Online\"] = [torch.from_numpy(f1).float()]\n",
    "    train_features[\"Offline\"] = [torch.from_numpy(f2).float()]\n",
    "    NUM_HIDDEN_LAYERS = 6\n",
    "    HIDDEN_DIM = 512\n",
    "    output_feature_size = 512\n",
    "    lr = 0.0001\n",
    "    epoch = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' temp = torch.from_numpy(b[\"x1\"]).float() # G1, features\\nprint(temp.shape)\\ntemp '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" temp = torch.from_numpy(b[\"x1\"]).float() # G1, features\n",
    "print(temp.shape)\n",
    "temp \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' temp = torch.from_numpy(b[\"x2\"]).float() # G2, features\\nprint(temp.shape)\\ntemp '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" temp = torch.from_numpy(b[\"x2\"]).float() # G2, features\n",
    "print(temp.shape)\n",
    "temp \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' temp = b[\"test_pairs\"]\\nprint(temp.shape)\\ntemp '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" temp = b[\"test_pairs\"]\n",
    "print(temp.shape)\n",
    "temp \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 6829],\n",
       "       [   2, 3102],\n",
       "       [   3, 3584],\n",
       "       ...,\n",
       "       [9841, 3392],\n",
       "       [9850,  306],\n",
       "       [9868, 9011]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACM', 'DBLP']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training datasets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ACM': [tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]])],\n",
       " 'DBLP': [tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]])]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = \"GIN\"\n",
    "use_input_augmentation = True\n",
    "use_output_augmentation = False\n",
    "print(\"Loading training datasets\")\n",
    "train_loader = {}\n",
    "for dataset in train_set:\n",
    "    train_loader[dataset] = [load_adj(dataset)]\n",
    "\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ACM', 'DBLP'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' temp = train_loader[\"ACM\"][0]\\nprint(temp.shape)\\ntemp '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" temp = train_loader[\"ACM\"][0]\n",
    "print(temp.shape)\n",
    "temp \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' temp = train_loader[\"DBLP\"][0]\\nprint(temp.shape)\\ntemp '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" temp = train_loader[\"DBLP\"][0]\n",
    "print(temp.shape)\n",
    "temp \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAE(\n",
       "  (base_gcn): GIN(\n",
       "    (in_proj): Linear(in_features=17, out_features=1024, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0-13): 14 x GINConv(\n",
       "        (linear): Linear(in_features=1041, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (out_proj): Linear(in_features=15360, out_features=1024, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GAE(NUM_HIDDEN_LAYERS,\n",
    "            input_dim,\n",
    "            HIDDEN_DIM,\n",
    "            output_feature_size, activation=F.relu,\n",
    "            use_input_augmentation=use_input_augmentation,\n",
    "            use_output_augmentation=use_output_augmentation,\n",
    "            encoder=encoder).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training features\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating training features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:41<00:00,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best results achieved:\n",
      "Hit@1: 0.7383399209486166\n",
      "Hit@5: 0.9142292490118578\n",
      "Hit@10: 0.950790513833992\n",
      "Hit@50: 0.9814229249011858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting model\")\n",
    "# fit_GAE_real(data, len(train_set) * (1 + 1), model, epoch, train_loader, train_features, device, lr,test_pairs)\n",
    "# fit_GAE_real(data, no_samples, GAE, epoch, train_loader, train_features, device, lr, test_pairs):\n",
    "\n",
    "no_samples = len(train_set) * (1 + 1)\n",
    "GAE = model\n",
    "# ---\n",
    "\n",
    "best_hitAtOne = 0\n",
    "best_hitAtFive = 0\n",
    "best_hitAtTen = 0\n",
    "best_hitAtFifty = 0\n",
    "optimizer = Adam(GAE.parameters(), lr=lr, weight_decay=5e-4)\n",
    "\n",
    "for step in tqdm(range(epoch)):\n",
    "    loss = 0\n",
    "    \n",
    "    for dataset in train_loader.keys():\n",
    "        S = train_loader[dataset][0]\n",
    "        initial_features = train_features[dataset]\n",
    "        \n",
    "        for i in range(len(train_loader[dataset])):\n",
    "            adj_tensor = train_loader[dataset][i]\n",
    "            adj = coo_matrix(adj_tensor.numpy())\n",
    "            adj_norm = preprocess_graph(adj)\n",
    "            pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
    "            norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    "\n",
    "            adj_label = coo_matrix(S.numpy())\n",
    "            adj_label = sparse_to_tuple(adj_label)\n",
    "\n",
    "            adj_norm = torch.sparse.FloatTensor(torch.LongTensor(adj_norm[0].T),\n",
    "                                                torch.FloatTensor(adj_norm[1]),\n",
    "                                                torch.Size(adj_norm[2])).to(device)\n",
    "            adj_label = torch.sparse.FloatTensor(torch.LongTensor(adj_label[0].T),\n",
    "                                                torch.FloatTensor(adj_label[1]),\n",
    "                                                torch.Size(adj_label[2])).to(device)\n",
    "\n",
    "            initial_feature = initial_features[i].to(device)\n",
    "\n",
    "            weight_mask = adj_label.to_dense().view(-1) == 1\n",
    "            weight_tensor = torch.ones(weight_mask.size(0))\n",
    "            weight_tensor[weight_mask] = pos_weight\n",
    "            weight_tensor = weight_tensor.to(device)\n",
    "            z = GAE(initial_feature, adj_norm)\n",
    "            A_pred = torch.sigmoid(torch.matmul(z,z.t()))\n",
    "            loss += norm * F.binary_cross_entropy(A_pred.view(-1), adj_label.to_dense().view(-1),\n",
    "                                                        weight=weight_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = loss / no_samples\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # ---\n",
    "    keys = list(train_loader.keys())\n",
    "    S1 = train_loader[keys[0]][0]\n",
    "    S2 = train_loader[keys[1]][0]\n",
    "    \n",
    "    adj_S1 = coo_matrix(S1.numpy())\n",
    "    adj_norm_1 = preprocess_graph(adj_S1)\n",
    "    adj_norm_1 = torch.sparse.FloatTensor(torch.LongTensor(adj_norm_1[0].T),\n",
    "                                            torch.FloatTensor(adj_norm_1[1]),\n",
    "                                            torch.Size(adj_norm_1[2])).to(device)\n",
    "    adj_S2 = coo_matrix(S2.numpy())\n",
    "    adj_norm_2 = preprocess_graph(adj_S2)\n",
    "    adj_norm_2 = torch.sparse.FloatTensor(torch.LongTensor(adj_norm_2[0].T),\n",
    "                                            torch.FloatTensor(adj_norm_2[1]),\n",
    "                                            torch.Size(adj_norm_2[2])).to(device)\n",
    "    if (data == \"ACM_DBLP\"):\n",
    "        S1_feat = train_features[\"ACM\"][0]\n",
    "        S2_feat = train_features[\"DBLP\"][0]\n",
    "    elif (data == \"Douban Online_Offline\"):\n",
    "        S1_feat = train_features[\"Online\"][0]\n",
    "        S2_feat = train_features[\"Offline\"][0]\n",
    "\n",
    "    # ---\n",
    "    S1_emb = GAE(S1_feat.to(device), adj_norm_1).detach()\n",
    "    S2_emb = GAE(S2_feat.to(device), adj_norm_2).detach()\n",
    "\n",
    "    D = torch.cdist(S1_emb, S2_emb, 2) # Euclidean distance\n",
    "    \n",
    "    if (data == \"ACM_DBLP\"):\n",
    "        test_idx = test_pairs[:, 0].astype(np.int32)\n",
    "        labels = test_pairs[:, 1].astype(np.int32)\n",
    "    elif (data == \"Douban Online_Offline\"):\n",
    "        test_idx = test_pairs[0, :].astype(np.int32)\n",
    "        labels = test_pairs[1, :].astype(np.int32)\n",
    "    \n",
    "    hitAtOne = 0\n",
    "    hitAtFive = 0\n",
    "    hitAtTen = 0\n",
    "    hitAtFifty = 0\n",
    "    hitAtHundred = 0\n",
    "    \n",
    "    # test\n",
    "    \n",
    "    for i in range(len(test_idx)): # here\n",
    "        dist_list = D[test_idx[i]]\n",
    "        # print(i, test_idx[i], dist_list)\n",
    "        sorted_neighbors = torch.argsort(dist_list).cpu()\n",
    "        label = labels[i]\n",
    "        \n",
    "        \"\"\" if i == 0:\n",
    "            print(label, sorted_neighbors[0].item(), sorted_neighbors)\n",
    "            # 6829 6829 tensor([6829, 3102,  601,  ..., 7878, 9701, 2044]) \"\"\"\n",
    "        \n",
    "        for j in range(100):\n",
    "            if (sorted_neighbors[j].item() == label):\n",
    "                if (j == 0):\n",
    "                    hitAtOne += 1\n",
    "                    hitAtFive += 1\n",
    "                    hitAtTen += 1\n",
    "                    hitAtFifty += 1\n",
    "                    hitAtHundred += 1\n",
    "                    break\n",
    "                elif (j <= 4):\n",
    "                    hitAtFive += 1\n",
    "                    hitAtTen += 1\n",
    "                    hitAtFifty += 1\n",
    "                    hitAtHundred += 1\n",
    "                    break\n",
    "                elif (j <= 9):\n",
    "                    hitAtTen += 1\n",
    "                    hitAtFifty += 1\n",
    "                    hitAtHundred += 1\n",
    "                    break\n",
    "                elif (j <= 49):\n",
    "                    hitAtFifty += 1\n",
    "                    hitAtHundred += 1\n",
    "                    break\n",
    "                elif (j <= 100):\n",
    "                    hitAtHundred += 1\n",
    "                    break\n",
    "    \n",
    "    cur_hitAtOne = hitAtOne / len(test_idx)\n",
    "    cur_hitAtFive = hitAtFive / len(test_idx)\n",
    "    cur_hitAtTen = hitAtTen / len(test_idx)\n",
    "    cur_hitAtFifty = hitAtFifty / len(test_idx)\n",
    "\n",
    "    if(cur_hitAtOne > best_hitAtOne): best_hitAtOne = cur_hitAtOne\n",
    "    if (cur_hitAtFive > best_hitAtFive): best_hitAtFive = cur_hitAtFive\n",
    "    if (cur_hitAtTen > best_hitAtTen): best_hitAtTen = cur_hitAtTen\n",
    "    if (cur_hitAtFifty > best_hitAtFifty): best_hitAtFifty = cur_hitAtFifty\n",
    "\n",
    "print(\"The best results achieved:\")\n",
    "print(\"Hit@1: \", end=\"\")\n",
    "print(best_hitAtOne)\n",
    "print(\"Hit@5: \", end=\"\")\n",
    "print(best_hitAtFive)\n",
    "print(\"Hit@10: \", end=\"\")\n",
    "print(best_hitAtTen)\n",
    "print(\"Hit@50: \", end=\"\")\n",
    "print(best_hitAtFifty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9872, 9916])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17.4764, 18.5462, 17.2963,  ..., 17.6960, 17.3824, 17.1963],\n",
       "        [15.8282, 14.8613, 15.4932,  ..., 15.9868, 15.6872, 15.5217],\n",
       "        [21.4269, 22.2469, 21.3279,  ..., 21.5871, 21.3105, 21.2061],\n",
       "        ...,\n",
       "        [ 2.2839,  4.6655,  1.1718,  ...,  3.6780,  2.2081,  1.9188],\n",
       "        [ 2.0562,  4.7448,  1.9882,  ...,  3.5978,  1.7922,  0.4190],\n",
       "        [ 1.8103,  4.8147,  1.8327,  ...,  3.5856,  1.4176,  1.3181]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACM_DBLP\n",
      "(5060, 2)\n",
      "[[   0 6829]\n",
      " [   2 3102]\n",
      " [   3 3584]\n",
      " ...\n",
      " [9841 3392]\n",
      " [9850  306]\n",
      " [9868 9011]]\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(test_pairs.shape)\n",
    "print(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5060, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3615,    1],\n",
       "       [1302,    2],\n",
       "       [ 466,    3],\n",
       "       ...,\n",
       "       [6148, 9907],\n",
       "       [3826, 9911],\n",
       "       [7275, 9915]], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (data == \"ACM_DBLP\"):\n",
    "    test_pairs_ = test_pairs\n",
    "elif (data == \"Douban Online_Offline\"):\n",
    "    test_pairs_ = test_pairs.T\n",
    "    \n",
    "truth = test_pairs_[test_pairs_[:, 1].argsort()]\n",
    "print(truth.shape)\n",
    "truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def hungarian(D):\n",
    "    print(\"0\")\n",
    "    P = torch.zeros_like(D)\n",
    "    matrix = D.tolist()\n",
    "    m = Munkres()\n",
    "    print(\"1\")\n",
    "    indexes = m.compute(matrix)\n",
    "    print(\"2\")\n",
    "    total = 0\n",
    "    for r, c in tqdm(indexes):\n",
    "        print(r)\n",
    "        P[r][c] = 1\n",
    "        total += matrix[r][c]\n",
    "    return P.t()\n",
    "\n",
    "P = hungarian(D)\n",
    "print(P.shape)\n",
    "# online_offline: 215m\n",
    "# acm_dblp: 1112m\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "\n",
    "X = P.cpu().numpy()\n",
    "np.save(\"P_hungarian_ACM_DBLP\", X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "\n",
    "P = np.load(\"P_hungarian.npy\")\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Hungarian (source code)\n",
    "option0 = []\n",
    "m, n = P.shape\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        if P[i][j] == 1:\n",
    "            option0.append([j, i]) # S, S_hat\n",
    "option0 = np.array(option0)\n",
    "print(len(option0))\n",
    "option0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching = test_matching(truth, option0)\n",
    "print(len(matching))\n",
    "print(len(matching) / len(truth))\n",
    "matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def hungarian_algorithm(cost_matrix):\n",
    "    # Use the linear_sum_assignment method from scipy\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    \n",
    "    # Total cost\n",
    "    total_cost = cost_matrix[row_ind, col_ind].sum()\n",
    "    \n",
    "    # The assignments are returned as (row, col) pairs\n",
    "    assignments = list(zip(row_ind, col_ind))\n",
    "    \n",
    "    return total_cost, assignments\n",
    "\n",
    "total_cost, assignments = hungarian_algorithm(D.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option1 = np.array(assignments)\n",
    "option1 = option1[option1[:, 1].argsort()]\n",
    "print(option1.shape)\n",
    "option1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching = test_matching(truth, option1)\n",
    "print(len(matching))\n",
    "print(len(matching) / len(truth))\n",
    "matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build graph\n",
    "def build_graph(adj_norm):\n",
    "    edges = adj_norm.coalesce().indices()\n",
    "\n",
    "    G = nx.from_edgelist(edges.T.cpu().numpy())\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    print(G.number_of_nodes(), G.number_of_edges())\n",
    "\n",
    "    return G\n",
    "\n",
    "G1 = build_graph(adj_norm_1)\n",
    "G2 = build_graph(adj_norm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos1 = nx.spring_layout(G1)\n",
    "pos2 = nx.spring_layout(G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "plt.title('Graph 1')\n",
    "nx.draw_networkx(G1, pos=pos1, font_color=\"w\")\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "plt.title('Graph 2')\n",
    "nx.draw_networkx(G2, pos=pos2, font_color=\"w\")\n",
    "\n",
    "# add connections\n",
    "for i in range(len(matching)):\n",
    "    con = ConnectionPatch(xyA=pos1[matching[i][0]], xyB=pos2[matching[i][1]], coordsA=ax1.transData, coordsB=ax2.transData, arrowstyle=\"-\", color=\"green\")\n",
    "    ax2.add_artist(con)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygmtools as pygm\n",
    "\n",
    "X = pygm.hungarian(D.cpu().numpy())\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "row, col = X.shape\n",
    "for i in range(row):\n",
    "    for j in range(col):\n",
    "        if X[i][j] == 1:\n",
    "            indices.append([i, j])\n",
    "option2 = np.array(indices)\n",
    "option2 = option2[option2[:, 1].argsort()]\n",
    "print(option2.shape)\n",
    "option2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching = test_matching(truth, option2)\n",
    "print(len(matching))\n",
    "print(len(matching) / len(truth))\n",
    "matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i in range(D.shape[0]):\n",
    "    dist_list = D[i]\n",
    "    sorted_neighbors = torch.argsort(dist_list).cpu()\n",
    "    indices.append([i, sorted_neighbors[0]])\n",
    "\n",
    "option3 = np.array(indices)\n",
    "option3 = option3[option3[:, 1].argsort()]\n",
    "print(option3.shape)\n",
    "option3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching = test_matching(truth, option3)\n",
    "print(len(matching))\n",
    "print(len(matching) / len(truth))\n",
    "matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[0.0,  0.0], [0.0, 1.0], [0.0,  2.0]])\n",
    "print(a)\n",
    "b = torch.tensor([[0.0, 1.0 ], [1.0,  1.0]])\n",
    "print(b)\n",
    "torch.cdist(a, b, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[4.01, 3.0, 2.0, 0.1, 4.0]])\n",
    "print(a)\n",
    "torch.argsort(a, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[9, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 0, 5]])\n",
    "\n",
    "a[a[:, 2].argsort()]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_alignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
